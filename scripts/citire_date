import time
import json
import pandas as pd
from kafka import KafkaProducer

# Configurare Kafka Producer
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda x: json.dumps(x).encode('utf-8'),
    key_serializer=lambda x: x.encode('utf-8')  # Folosim cheie pentru scalabilitate
)

TOPIC_NAME = 'iot_sensors'
CSV_FILE_PATH = "iot_telemetry_data.csv"

def run_simulation():
    print(f"Începem simularea citirii datelor din {CSV_FILE_PATH}...")
    
    # Citim CSV-ul.
    # header=1 înseamnă că folosim al doilea rând (index 1) ca nume de coloane (ts, device, co, etc.)
    # chunksize=1000 ne ajută să citim fișierul bucată cu bucată, eficient
    for chunk in pd.read_csv(CSV_FILE_PATH, sep=',', header=0, chunksize=1000):
        
        for index, row in chunk.iterrows():
            # Convertim rândul la dicționar
            sensor_data = row.to_dict()
            # Cheia de partiționare: Device ID
            # Asta asigură scalabilitatea: datele aceluiași senzor merg mereu în aceeași partiție,
            # dar senzorii diferiți sunt distribuiți pe cele 3 partiții.
            device_id = str(sensor_data['device'])
            
            # Trimitem mesajul către Kafka
            producer.send(TOPIC_NAME, key=device_id, value=sensor_data)
            
            print(f"Trimis: {device_id} -> {sensor_data['ts']}")
            
            # Simulăm o mică pauză (ex: 0.01 secunde) pentru a nu trimite totul instantaneu
            # Poți mări timpul dacă vrei să vezi fluxul mai lent
            time.sleep(0.01)
            
        # Golim buffer-ul periodic
        producer.flush()

if __name__ == "__main__":
    try:
        run_simulation()
    except KeyboardInterrupt:
        print("Simulare oprită.")
    except Exception as e:
        print(f"Eroare: {e}")
    finally:
        producer.close()